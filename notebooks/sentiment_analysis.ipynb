{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15fc914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(\"All imports ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad784481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8518, 8)\n",
      "\n",
      "Columns: ['Reviewer Name', 'Review Title', 'Place of Review', 'Up Votes', 'Down Votes', 'Month', 'Review text', 'Ratings']\n",
      "\n",
      "Rating distribution:\n",
      "Ratings\n",
      "1     769\n",
      "2     308\n",
      "3     615\n",
      "4    1746\n",
      "5    5080\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Null values:\n",
      "Reviewer Name       10\n",
      "Review Title        10\n",
      "Place of Review     50\n",
      "Up Votes            10\n",
      "Down Votes          10\n",
      "Month              465\n",
      "Review text          8\n",
      "Ratings              0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment balance: {1: 6823, 0: 1687}\n"
     ]
    }
   ],
   "source": [
    "# Data Loading + Analysis \n",
    "# Load dataset\n",
    "df = pd.read_csv('C:/Users/chinm/OneDrive/Desktop/flipkart_sentiment/data/data.csv', encoding='latin-1')\n",
    "\n",
    "# Basic analysis\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nRating distribution:\")\n",
    "print(df['Ratings'].value_counts().sort_index())\n",
    "print(\"\\nNull values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Create binary sentiment (positive=4-5, negative=1-3)\n",
    "df = df.dropna(subset=['Review text', 'Ratings'])\n",
    "df['sentiment'] = df['Ratings'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "print(f\"\\nSentiment balance: {df['sentiment'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145b69f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data: (8359, 10)\n",
      "Sample cleaned: nice product nice product good quality but price is now rising which is a bad sign was an affordable...\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning (Text Cleaning & Normalization)\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove special chars, normalize (satisfies preprocessing req)\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text)  # URLs\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)                 # Special chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()              # Spaces\n",
    "    return text\n",
    "\n",
    "# Clean, combine title & review text\n",
    "df['Review Title'] = df['Review Title'].fillna('')\n",
    "df['full_text'] = (df['Review Title'] + ' ' + df['Review text']).apply(clean_text)\n",
    "df = df[df['full_text'].str.len() > 20]  # Drop too short\n",
    "\n",
    "print(\"Cleaned data:\", df.shape)\n",
    "print(\"Sample cleaned:\", df['full_text'].iloc[0][:100] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features:\n",
      "Train: (6687, 5004)\n",
      "Test: (1672, 5004)\n",
      "Train balance: {1: np.int64(5357), 0: np.int64(1330)}\n"
     ]
    }
   ],
   "source": [
    "# Text Embedding - TF-IDF \n",
    "X = df['full_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF (Bag-of-Words + TF-IDF required)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 3),  # Up to trigrams\n",
    "    min_df=3,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF features:\")\n",
    "print(f\"Train: {X_train_tfidf.shape}\")\n",
    "print(f\"Test: {X_test_tfidf.shape}\")\n",
    "print(\"Train balance:\", dict(y_train.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154ce165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained!\n"
     ]
    }
   ],
   "source": [
    "# Model Training (ML Models)\n",
    "# Logistic Regression \n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weights = {cls: w for cls, w in zip(classes, weights)}\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=3000, \n",
    "    random_state=42,\n",
    "    C=0.5,                    \n",
    "    class_weight=class_weights \n",
    ")\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7faf3090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL PERFORMANCE:\n",
      "F1-Score: 0.918\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71       333\n",
      "           1       0.94      0.90      0.92      1339\n",
      "\n",
      "    accuracy                           0.87      1672\n",
      "   macro avg       0.80      0.84      0.81      1672\n",
      "weighted avg       0.88      0.87      0.88      1672\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted    0     1\n",
      "Actual              \n",
      "0          259    74\n",
      "1          139  1200\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation - F1-Score \n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"MODEL PERFORMANCE:\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(\"\\nDetailed Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78b86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE NEGATIVE PAIN POINTS:\n",
      "  quality      518\n",
      "  shuttl       286\n",
      "  shuttles     168\n",
      "  money        156\n",
      "  worst        144\n",
      "  purchas      119\n",
      "  wast         102\n",
      "  damag         95\n",
      "  awesom        79\n",
      "  flipkart      72\n",
      "  bett          70\n",
      "  original      69\n",
      "  days          67\n",
      "  disappoint    66\n",
      "  recommen      59\n",
      "\n",
      "Negative review examples:\n",
      "1. don t waste your money they didn t supplied yonex mavis outside cover was yonex ad inside was a cheapest sad to hear thi...\n",
      "2. did not meet expectations worst product damaged shuttlecocks packed in new box it s not a original yonex product don t b...\n",
      "3. fair quite o k but nowadays the quality of the corks like not as before to years back i am using mavis for more than yea...\n"
     ]
    }
   ],
   "source": [
    "# Pain Points Analysis (Objective: dissatisfaction insights)\n",
    "neg_reviews = df[df['sentiment'] == 0]['full_text']\n",
    "\n",
    "# CLEAN STOPWORDS + \"READ MORE\" artifacts\n",
    "stop_words = {\n",
    "    'the', 'and', 'for', 'are', 'but', 'this', 'with', 'one', 'get', 'now', 'very', \n",
    "    'more', 'good', 'product', 'read', 'shuttle', 'will', 'from', 'just', 'nice',\n",
    "    'time', 'only', 'purchase', 'worth', 'terrific', 'awesome', 'mavis'\n",
    "}\n",
    "\n",
    "# SPLIT \"readmore\" artifacts\n",
    "neg_words = []\n",
    "for text in neg_reviews:\n",
    "    # Fix \"goodread\" â†’ \"good\" + \"read\"\n",
    "    text = re.sub(r'read$', '', text)  # Remove \"read\" suffix\n",
    "    words = text.split()\n",
    "    words = [w.rstrip('read') for w in words]  # Strip \"read\" endings\n",
    "    words = [w for w in words if len(w) > 3 and w not in stop_words]\n",
    "    neg_words.extend(words)\n",
    "\n",
    "print(\"TRUE NEGATIVE PAIN POINTS:\")\n",
    "pain_points = Counter(neg_words).most_common(15)\n",
    "for word, count in pain_points:\n",
    "    print(f\"  {word:<12} {count:3d}\")\n",
    "\n",
    "print(\"\\nNegative review examples:\")\n",
    "for i, review in enumerate(neg_reviews.head(3)):\n",
    "    print(f\"{i+1}. {review[:120]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8818292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "# Save \n",
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(model, '../models/model.pkl')\n",
    "joblib.dump(tfidf, '../models/tfidf.pkl')\n",
    "\n",
    "print(\"SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb728e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
